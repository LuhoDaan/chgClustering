{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TFIDF full score approach\n",
        "**to overcome knowing the n° of clusters**"
      ],
      "metadata": {
        "id": "yCzVRTe-e-yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "\n"
      ],
      "metadata": {
        "id": "q23j4AR3gxgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "from unidecode import unidecode"
      ],
      "metadata": {
        "id": "AG6cxF6lt8vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d0ba2b-a54e-4843-b193-16b6e88108ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m194.6/235.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_EXTRACTION = \"/content/change_request (7).xlsx\"#\"/content/estrazione_chg_emergency.xlsx\""
      ],
      "metadata": {
        "id": "K-6djeUlg4lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"ZIPPING FUNCTION\"\"\"\n",
        "\n",
        "def zip_it_multiple_files():\n",
        "    excel_dir = '/content/excel_files/'\n",
        "\n",
        "    # Iterate over the DataFrame list and save each DataFrame as an Excel file\n",
        "    for i, df in enumerate(df_list_labels_per_machine):\n",
        "        # Construct the directory path based on the machine name\n",
        "        machine_name = list_of_machines_ordered[i]\n",
        "        machine_dir = os.path.join(excel_dir, machine_name)\n",
        "\n",
        "        # Ensure that the directory exists, creating it if necessary\n",
        "        os.makedirs(machine_dir, exist_ok=True)\n",
        "\n",
        "        # Construct the Excel file name\n",
        "        excel_file_name = f\"{machine_name.replace('/', '_')}.xlsx\"  # Replace '/' with another character\n",
        "        excel_file_path = os.path.join(machine_dir, excel_file_name)\n",
        "\n",
        "        # Save the DataFrame to the Excel file\n",
        "        df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "    # Create a zip file containing all Excel files\n",
        "    with zipfile.ZipFile('/content/data.zip', 'w') as zipf:\n",
        "        for root, dirs, files in os.walk(excel_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zipf.write(file_path, arcname=file)\n",
        "\n",
        "    # Download the zip file (Colab specific)\n",
        "    from google.colab import files\n",
        "    files.download('/content/data.zip')"
      ],
      "metadata": {
        "id": "2eHqWvnXU-eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "bu_cK4yeg7JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "#dove viene usato punkt?\n",
        "nltk.download('punkt')\n",
        "sequence_to_remove = ['descrizione del problema', 'analisi e soluzione','modifica','emergenza','intervento','eseguito','produzione','appeso','-', 'EMERGENCY', 'DATA', 'SUPPORT', 'MICS-SHARED', 'macchina', 'PA', '\"Linea', 'Modifica', 'MI&CS', 'di', 'Filling', 'Problema', 'su', 'MICS', 'PFS', 'per', 'SESTO', 'Esecuzione', 'Emergency','<']\n",
        "stop_words = set(nltk.corpus.stopwords.words('italian') + [])\n",
        "\n",
        "def data_cleaning_bow(dataframe):\n",
        "    def text_cleaning(text_raw):\n",
        "        text_filtered = text_raw.lower()  # lowercase\n",
        "        # remove text after '***Dati Modificati***'\n",
        "        text_filtered = re.sub('\\n.*'+'dati modificati'+'.*', ' ', text_filtered)\n",
        "        # remove section separators\n",
        "        for el in sequence_to_remove:\n",
        "            #text_filtered = re.sub('\\n.*'+el+'.*\\n', ' ', text_filtered)\n",
        "            text_filtered = re.sub(r'\\b{}\\b'.format(re.escape(el)), '', text_filtered)\n",
        "        # clean and standardize the text\n",
        "        text_filtered = unidecode(text_filtered)  # remove accents\n",
        "        text_filtered = re.sub('[^A-Za-z0-9_ ]+', ' ', text_filtered)\n",
        "        #why tokenize now ? Does it interacts with the following tokenization of the vectorizer?\n",
        "        words = nltk.word_tokenize(text_filtered, language=\"italian\")  # tokenize\n",
        "        filtered_sentence = [w for w in words if w not in stop_words]  # remove stopwords\n",
        "        return filtered_sentence\n",
        "\n",
        "    def extract_bag_of_words(row):\n",
        "        input_text = row[\"Short Description\"] + \" \" + row[\"Description\"]\n",
        "        input_cleaned = text_cleaning(input_text)\n",
        "        return ' '.join(input_cleaned)\n",
        "\n",
        "    dataframe[\"BoW\"] = dataframe.apply(extract_bag_of_words, axis=1)\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "tOly4ce2hLbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ec307b-90f2-457b-e510-c5b2652df90e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorization"
      ],
      "metadata": {
        "id": "wJpxAtaANDL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tf_idf(dataframe):\n",
        "    # Initialize the vectorizer\n",
        "    vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Fit and transform the corpus\n",
        "    tfidf_matrix = vectorizer.fit_transform(list(dataframe['BoW']))\n",
        "\n",
        "    return vectorizer, tfidf_matrix\n",
        "\n",
        "\n",
        "def get_test_scores(vectorizer,matrix_bucket):\n",
        "    #sentence = [sentence]\n",
        "    tfidf_matrix_bucket = vectorizer.transform(matrix_bucket)\n",
        "    scores = cosine_similarity(tfidf_matrix_bucket, tfidf_matrix_bucket)\n",
        "    scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
        "    return scores_normed\n",
        "\n",
        "def eliminate_duplicates(df):\n",
        "    # Sort the groups based on the length of unique 'Number' values to ensure larger groups are compared first.\n",
        "    # This makes it easier to identify subsets since a larger group cannot be a subset of a smaller one.\n",
        "    grouped_df = df.groupby('labels', as_index=False)\n",
        "    groups = [group for _, group in grouped_df]\n",
        "    groups.sort(key=lambda x: len(set(x['Number'])), reverse=True)\n",
        "\n",
        "    to_remove = []\n",
        "    for i in range(len(groups) - 1):\n",
        "        if i in to_remove:\n",
        "            continue\n",
        "        for j in range(i + 1, len(groups)):\n",
        "            if j in to_remove:\n",
        "                continue\n",
        "            set_i = set(groups[i]['Number'])\n",
        "            set_j = set(groups[j]['Number'])\n",
        "\n",
        "            # If set_j is a subset of set_i, mark set_j for removal\n",
        "            if set_j.issubset(set_i):\n",
        "                to_remove.append(j)\n",
        "            # Alternatively, if set_i is a subset of set_j, mark set_i for removal\n",
        "            elif set_i.issubset(set_j):\n",
        "                to_remove.append(i)\n",
        "                break  # No need to compare i with other groups if it's already marked for removal\n",
        "\n",
        "    # Remove identified subsets\n",
        "    final_groups = [group for index, group in enumerate(groups) if index not in to_remove]\n",
        "\n",
        "    # Concatenate the remaining groups\n",
        "    result_df = pd.concat(final_groups).reset_index(drop=True)\n",
        "    return result_df\n",
        "\n",
        "\n",
        "def clusterize(df_with_labels, df_clean, scores, similarity_threshold):\n",
        "    # Assuming 'scores' is defined outside this function and is accessible here.\n",
        "    # 'scores' should be a 2D array or DataFrame of similarity scores between rows.\n",
        "\n",
        "    df_clean['labels'] = 'Gruppo_0'  # Initialize all labels to a default group\n",
        "    cluster_label_counter = 0  # Initialize cluster counter\n",
        "\n",
        "    for i in range(len(df_clean)):\n",
        "        similar_indices = np.where(scores[:, i] > similarity_threshold)[0]\n",
        "        if len(similar_indices) > 0:\n",
        "            cluster_label = f'label_{cluster_label_counter}'\n",
        "            df_clean.loc[similar_indices, 'labels'] = cluster_label\n",
        "            cluster_label_counter += 1  # Increment for a new cluster label in the next iteration\n",
        "\n",
        "    # Now, all entries have been assigned to clusters based on similarity.\n",
        "    # Concatenate with df_with_labels if needed (assuming df_with_labels is initially empty or needs updating).\n",
        "        df_with_labels = pd.concat([df_with_labels, df_clean.loc[similar_indices].drop('BoW', axis=1)], ignore_index=True)\n",
        "\n",
        "    # Before removing duplicates, let's see the size\n",
        "    print(f\"BEFORE DUPLICATES REMOVAL {df_with_labels.shape[0]}\")\n",
        "    df_with_labels = eliminate_duplicates(df_with_labels)  # Assuming this function is optimized as discussed.\n",
        "    print(f\"END NUMBER ELEMENTS {df_with_labels.shape[0]}\")\n",
        "\n",
        "    return df_with_labels"
      ],
      "metadata": {
        "id": "bTE85xcPuqzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Maybe use panel to portray a report of most frequent configuration items"
      ],
      "metadata": {
        "id": "An4ferH9WWlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def main():\n",
        "df = pd.read_excel(INPUT_EXTRACTION,sheet_name='Page 1')\n",
        "list_of_machines_ordered = list(df['Configuration Item'].value_counts().index)\n",
        "similarity_threshold = 0.7\n",
        "#Create a list containing the various df's, one for each configuration item\n",
        "df_list_per_machine = []\n",
        "#Create list of df's with labels, one for each configuration item\n",
        "df_list_labels_per_machine = []\n",
        "for i, machine_name in enumerate(list_of_machines_ordered):\n",
        "    #if i == 0:\n",
        "     # continue\n",
        "    df_filtered = df[df['Configuration Item'] == machine_name].copy(deep=True).reset_index(drop = True)\n",
        "    df_list_per_machine.append(df_filtered)\n",
        "\n",
        "#index to keep track of how many times we didn't even had the risk of having duplicates\n",
        "list_of_elimination_dulicates= []\n",
        "i= 0\n",
        "for df_raw in df_list_per_machine:\n",
        "  i+=1\n",
        "  df_clean = data_cleaning_bow(df_raw)\n",
        "  #Instantiate a new dataframe that will add the labels to each row\n",
        "  df_with_labels = pd.DataFrame(columns = df_clean.columns)\n",
        "  #clusters = {}\n",
        "  #Initialize Vectorizer fitted for each ci's vocabulary only\n",
        "  vectorizer = TfidfVectorizer().fit(list(df_clean['BoW']))\n",
        "  #Compute diverse scores, generating an nxn matrix. Each column represents an individual emergency (i-th), while the rows below it display the cosine similarity scores with respect to the j-th emergency\n",
        "  scores = get_test_scores(vectorizer, list(df_clean['BoW']))\n",
        "  #populate the new dataframe with the relevant labels\n",
        "  print(f\"Machine {i}\")\n",
        "  print(f\"BEFORE CLUSTERING{df_clean.shape[0]}\")\n",
        "  if df_clean.shape[0] == 1:\n",
        "    df_with_labels = df_clean.copy(deep=True).reset_index(drop = True)\n",
        "    df_with_labels['labels'] = 'Gruppo_0'\n",
        "  else:\n",
        "    if i == 1:\n",
        "      df_with_labels = clusterize(df_with_labels,df_clean,scores,0.825)\n",
        "    else:\n",
        "      df_with_labels = clusterize(df_with_labels,df_clean,scores,similarity_threshold)\n",
        "  df_list_labels_per_machine.append(df_with_labels)\n",
        "\n",
        "\n",
        "\n",
        "df_only = pd.concat(df_list_labels_per_machine,ignore_index=True)\n",
        "df_only.to_excel('excel_label_removed_duplicates.xlsx')\n",
        "\n",
        "# Call the function to ZIP\n",
        "#zip_it_multiple_files()\n",
        "#main()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ENceSzXU2yM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152f2f22-88aa-4cf4-a0de-83e34092ab08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine 1\n",
            "BEFORE CLUSTERING99\n",
            "BEFORE DUPLICATES REMOVAL 143\n",
            "END NUMBER ELEMENTS 99\n",
            "Machine 2\n",
            "BEFORE CLUSTERING89\n",
            "BEFORE DUPLICATES REMOVAL 199\n",
            "END NUMBER ELEMENTS 128\n",
            "Machine 3\n",
            "BEFORE CLUSTERING67\n",
            "BEFORE DUPLICATES REMOVAL 151\n",
            "END NUMBER ELEMENTS 70\n",
            "Machine 4\n",
            "BEFORE CLUSTERING60\n",
            "BEFORE DUPLICATES REMOVAL 94\n",
            "END NUMBER ELEMENTS 60\n",
            "Machine 5\n",
            "BEFORE CLUSTERING52\n",
            "BEFORE DUPLICATES REMOVAL 64\n",
            "END NUMBER ELEMENTS 52\n",
            "Machine 6\n",
            "BEFORE CLUSTERING48\n",
            "BEFORE DUPLICATES REMOVAL 144\n",
            "END NUMBER ELEMENTS 48\n",
            "Machine 7\n",
            "BEFORE CLUSTERING47\n",
            "BEFORE DUPLICATES REMOVAL 63\n",
            "END NUMBER ELEMENTS 47\n",
            "Machine 8\n",
            "BEFORE CLUSTERING45\n",
            "BEFORE DUPLICATES REMOVAL 61\n",
            "END NUMBER ELEMENTS 45\n",
            "Machine 9\n",
            "BEFORE CLUSTERING35\n",
            "BEFORE DUPLICATES REMOVAL 37\n",
            "END NUMBER ELEMENTS 35\n",
            "Machine 10\n",
            "BEFORE CLUSTERING32\n",
            "BEFORE DUPLICATES REMOVAL 44\n",
            "END NUMBER ELEMENTS 32\n",
            "Machine 11\n",
            "BEFORE CLUSTERING28\n",
            "BEFORE DUPLICATES REMOVAL 30\n",
            "END NUMBER ELEMENTS 28\n",
            "Machine 12\n",
            "BEFORE CLUSTERING27\n",
            "BEFORE DUPLICATES REMOVAL 35\n",
            "END NUMBER ELEMENTS 27\n",
            "Machine 13\n",
            "BEFORE CLUSTERING26\n",
            "BEFORE DUPLICATES REMOVAL 26\n",
            "END NUMBER ELEMENTS 26\n",
            "Machine 14\n",
            "BEFORE CLUSTERING24\n",
            "BEFORE DUPLICATES REMOVAL 44\n",
            "END NUMBER ELEMENTS 24\n",
            "Machine 15\n",
            "BEFORE CLUSTERING23\n",
            "BEFORE DUPLICATES REMOVAL 25\n",
            "END NUMBER ELEMENTS 23\n",
            "Machine 16\n",
            "BEFORE CLUSTERING21\n",
            "BEFORE DUPLICATES REMOVAL 33\n",
            "END NUMBER ELEMENTS 21\n",
            "Machine 17\n",
            "BEFORE CLUSTERING21\n",
            "BEFORE DUPLICATES REMOVAL 25\n",
            "END NUMBER ELEMENTS 21\n",
            "Machine 18\n",
            "BEFORE CLUSTERING19\n",
            "BEFORE DUPLICATES REMOVAL 29\n",
            "END NUMBER ELEMENTS 19\n",
            "Machine 19\n",
            "BEFORE CLUSTERING17\n",
            "BEFORE DUPLICATES REMOVAL 33\n",
            "END NUMBER ELEMENTS 17\n",
            "Machine 20\n",
            "BEFORE CLUSTERING17\n",
            "BEFORE DUPLICATES REMOVAL 89\n",
            "END NUMBER ELEMENTS 17\n",
            "Machine 21\n",
            "BEFORE CLUSTERING16\n",
            "BEFORE DUPLICATES REMOVAL 18\n",
            "END NUMBER ELEMENTS 16\n",
            "Machine 22\n",
            "BEFORE CLUSTERING16\n",
            "BEFORE DUPLICATES REMOVAL 16\n",
            "END NUMBER ELEMENTS 16\n",
            "Machine 23\n",
            "BEFORE CLUSTERING15\n",
            "BEFORE DUPLICATES REMOVAL 83\n",
            "END NUMBER ELEMENTS 31\n",
            "Machine 24\n",
            "BEFORE CLUSTERING14\n",
            "BEFORE DUPLICATES REMOVAL 32\n",
            "END NUMBER ELEMENTS 14\n",
            "Machine 25\n",
            "BEFORE CLUSTERING11\n",
            "BEFORE DUPLICATES REMOVAL 17\n",
            "END NUMBER ELEMENTS 11\n",
            "Machine 26\n",
            "BEFORE CLUSTERING10\n",
            "BEFORE DUPLICATES REMOVAL 12\n",
            "END NUMBER ELEMENTS 10\n",
            "Machine 27\n",
            "BEFORE CLUSTERING10\n",
            "BEFORE DUPLICATES REMOVAL 10\n",
            "END NUMBER ELEMENTS 10\n",
            "Machine 28\n",
            "BEFORE CLUSTERING9\n",
            "BEFORE DUPLICATES REMOVAL 13\n",
            "END NUMBER ELEMENTS 9\n",
            "Machine 29\n",
            "BEFORE CLUSTERING8\n",
            "BEFORE DUPLICATES REMOVAL 10\n",
            "END NUMBER ELEMENTS 8\n",
            "Machine 30\n",
            "BEFORE CLUSTERING7\n",
            "BEFORE DUPLICATES REMOVAL 7\n",
            "END NUMBER ELEMENTS 7\n",
            "Machine 31\n",
            "BEFORE CLUSTERING6\n",
            "BEFORE DUPLICATES REMOVAL 6\n",
            "END NUMBER ELEMENTS 6\n",
            "Machine 32\n",
            "BEFORE CLUSTERING5\n",
            "BEFORE DUPLICATES REMOVAL 13\n",
            "END NUMBER ELEMENTS 5\n",
            "Machine 33\n",
            "BEFORE CLUSTERING5\n",
            "BEFORE DUPLICATES REMOVAL 7\n",
            "END NUMBER ELEMENTS 5\n",
            "Machine 34\n",
            "BEFORE CLUSTERING5\n",
            "BEFORE DUPLICATES REMOVAL 5\n",
            "END NUMBER ELEMENTS 5\n",
            "Machine 35\n",
            "BEFORE CLUSTERING5\n",
            "BEFORE DUPLICATES REMOVAL 7\n",
            "END NUMBER ELEMENTS 5\n",
            "Machine 36\n",
            "BEFORE CLUSTERING3\n",
            "BEFORE DUPLICATES REMOVAL 5\n",
            "END NUMBER ELEMENTS 3\n",
            "Machine 37\n",
            "BEFORE CLUSTERING3\n",
            "BEFORE DUPLICATES REMOVAL 3\n",
            "END NUMBER ELEMENTS 3\n",
            "Machine 38\n",
            "BEFORE CLUSTERING3\n",
            "BEFORE DUPLICATES REMOVAL 5\n",
            "END NUMBER ELEMENTS 3\n",
            "Machine 39\n",
            "BEFORE CLUSTERING3\n",
            "BEFORE DUPLICATES REMOVAL 5\n",
            "END NUMBER ELEMENTS 3\n",
            "Machine 40\n",
            "BEFORE CLUSTERING3\n",
            "BEFORE DUPLICATES REMOVAL 3\n",
            "END NUMBER ELEMENTS 3\n",
            "Machine 41\n",
            "BEFORE CLUSTERING3\n",
            "BEFORE DUPLICATES REMOVAL 3\n",
            "END NUMBER ELEMENTS 3\n",
            "Machine 42\n",
            "BEFORE CLUSTERING2\n",
            "BEFORE DUPLICATES REMOVAL 2\n",
            "END NUMBER ELEMENTS 2\n",
            "Machine 43\n",
            "BEFORE CLUSTERING2\n",
            "BEFORE DUPLICATES REMOVAL 2\n",
            "END NUMBER ELEMENTS 2\n",
            "Machine 44\n",
            "BEFORE CLUSTERING2\n",
            "BEFORE DUPLICATES REMOVAL 2\n",
            "END NUMBER ELEMENTS 2\n",
            "Machine 45\n",
            "BEFORE CLUSTERING2\n",
            "BEFORE DUPLICATES REMOVAL 2\n",
            "END NUMBER ELEMENTS 2\n",
            "Machine 46\n",
            "BEFORE CLUSTERING2\n",
            "BEFORE DUPLICATES REMOVAL 2\n",
            "END NUMBER ELEMENTS 2\n",
            "Machine 47\n",
            "BEFORE CLUSTERING2\n",
            "BEFORE DUPLICATES REMOVAL 2\n",
            "END NUMBER ELEMENTS 2\n",
            "Machine 48\n",
            "BEFORE CLUSTERING2\n",
            "BEFORE DUPLICATES REMOVAL 2\n",
            "END NUMBER ELEMENTS 2\n",
            "Machine 49\n",
            "BEFORE CLUSTERING2\n",
            "BEFORE DUPLICATES REMOVAL 2\n",
            "END NUMBER ELEMENTS 2\n",
            "Machine 50\n",
            "BEFORE CLUSTERING2\n",
            "BEFORE DUPLICATES REMOVAL 2\n",
            "END NUMBER ELEMENTS 2\n",
            "Machine 51\n",
            "BEFORE CLUSTERING2\n",
            "BEFORE DUPLICATES REMOVAL 2\n",
            "END NUMBER ELEMENTS 2\n",
            "Machine 52\n",
            "BEFORE CLUSTERING1\n",
            "Machine 53\n",
            "BEFORE CLUSTERING1\n",
            "Machine 54\n",
            "BEFORE CLUSTERING1\n",
            "Machine 55\n",
            "BEFORE CLUSTERING1\n",
            "Machine 56\n",
            "BEFORE CLUSTERING1\n",
            "Machine 57\n",
            "BEFORE CLUSTERING1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine 58\n",
            "BEFORE CLUSTERING1\n",
            "Machine 59\n",
            "BEFORE CLUSTERING1\n",
            "Machine 60\n",
            "BEFORE CLUSTERING1\n",
            "Machine 61\n",
            "BEFORE CLUSTERING1\n",
            "Machine 62\n",
            "BEFORE CLUSTERING1\n",
            "Machine 63\n",
            "BEFORE CLUSTERING1\n",
            "Machine 64\n",
            "BEFORE CLUSTERING1\n",
            "Machine 65\n",
            "BEFORE CLUSTERING1\n",
            "Machine 66\n",
            "BEFORE CLUSTERING1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine 67\n",
            "BEFORE CLUSTERING1\n",
            "Machine 68\n",
            "BEFORE CLUSTERING1\n",
            "Machine 69\n",
            "BEFORE CLUSTERING1\n",
            "Machine 70\n",
            "BEFORE CLUSTERING1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
            "<ipython-input-6-2aed3fa7ad08>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  scores_normed = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_list_labels_per_machine[49]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "bxWDPSVwV4qr",
        "outputId": "e3cd04e3-201f-46c1-bec7-1f988af9b7a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Number                                  Short Description  \\\n",
              "0  CHG1686242  MI&CS PA - EMERGENCY - CERES - XFPMAQW12FL - E...   \n",
              "1  CHG1686765  MI&CS PA - EMERGENCY - CERES - XFPMAQW12FL, XF...   \n",
              "\n",
              "                                         Description              Opened  \\\n",
              "0  ***** DESCRIZIONE DEL PROBLEMA *****\\nDurante ... 2020-12-08 00:09:15   \n",
              "1  ***** DESCRIZIONE DEL PROBLEMA *****\\nDurante ... 2020-12-09 00:17:47   \n",
              "\n",
              "                         Configuration Item              Closed  BoW   labels  \n",
              "0  SESTO Palltronic SCADA AquaWIT - PRD 1.0 2021-01-07 08:55:23  NaN  label_0  \n",
              "1  SESTO Palltronic SCADA AquaWIT - PRD 1.0 2021-01-11 09:26:20  NaN  label_1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2aaec08e-4340-4042-bcaf-8c56bda068c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number</th>\n",
              "      <th>Short Description</th>\n",
              "      <th>Description</th>\n",
              "      <th>Opened</th>\n",
              "      <th>Configuration Item</th>\n",
              "      <th>Closed</th>\n",
              "      <th>BoW</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CHG1686242</td>\n",
              "      <td>MI&amp;CS PA - EMERGENCY - CERES - XFPMAQW12FL - E...</td>\n",
              "      <td>***** DESCRIZIONE DEL PROBLEMA *****\\nDurante ...</td>\n",
              "      <td>2020-12-08 00:09:15</td>\n",
              "      <td>SESTO Palltronic SCADA AquaWIT - PRD 1.0</td>\n",
              "      <td>2021-01-07 08:55:23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>label_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CHG1686765</td>\n",
              "      <td>MI&amp;CS PA - EMERGENCY - CERES - XFPMAQW12FL, XF...</td>\n",
              "      <td>***** DESCRIZIONE DEL PROBLEMA *****\\nDurante ...</td>\n",
              "      <td>2020-12-09 00:17:47</td>\n",
              "      <td>SESTO Palltronic SCADA AquaWIT - PRD 1.0</td>\n",
              "      <td>2021-01-11 09:26:20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>label_1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2aaec08e-4340-4042-bcaf-8c56bda068c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2aaec08e-4340-4042-bcaf-8c56bda068c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2aaec08e-4340-4042-bcaf-8c56bda068c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41b1d84d-72df-40ef-ae61-a72832d4fefd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41b1d84d-72df-40ef-ae61-a72832d4fefd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41b1d84d-72df-40ef-ae61-a72832d4fefd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = ['CHG2038328', 'CHG2272738', 'CHG2289064', 'CHG2342485']\n",
        "list2 = ['CHG2279054', 'CHG2279656','CHG2289064']\n",
        "\n",
        "res3 = all([ele in list1 for ele in list2])"
      ],
      "metadata": {
        "id": "GrpyfAaaoH8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len([i for i in list_of_elimination_dulicates if i == False]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtj_A7VPo3xd",
        "outputId": "ffbfc4cd-760f-441d-900c-3b3b17593606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"OLD ALGORITHM\"\"\"\n",
        "# def eliminate_duplicates(labels, df):\n",
        "#     df_list = []\n",
        "#     for label in labels:\n",
        "#         df_lab = df[df['labels'] == label].copy(deep=True).reset_index(drop = True)\n",
        "#         df_list.append(df_lab)\n",
        "#     bad_indexes = []\n",
        "#     for i in range(len(df_list)):\n",
        "#       chg_i = df_list[i]['Number'].values\n",
        "#       for j in range(len(df_list)):\n",
        "#         if i!=j:\n",
        "#           chg_j = df_list[j]['Number'].values\n",
        "#           is_matching = True\n",
        "#           #qui non va bene(immaginiamo il caso che chg_j sia più piccolo ma sia contenuto in chg_i...non verrebbe eliminato).\n",
        "#           #La soluzione è riscrivere il ciclo di modo che sia possibile controllare anche in direzione contraria(l'ottimizazzione che si perde è un fattore costante..vedi gauss)\n",
        "#           if len(chg_i) > len(chg_j):\n",
        "#             continue\n",
        "#           for el in chg_i:\n",
        "#             #questo deve verificarsi per ogni chg_j..altrimenti vuol dire che chg_i è duplicato da qualcuno\n",
        "#             if not (el in chg_j ):\n",
        "#               is_matching = False\n",
        "#               break\n",
        "#           if is_matching:\n",
        "#             bad_indexes.append(i)\n",
        "#             #added this break since the previous brake only exited the first inner loop 'for el in chg_i'\n",
        "#             break\n",
        "\n",
        "#     result_df = [df_list[i] for i in range(len(df_list)) if i not in bad_indexes]\n",
        "#     if len(result_df)>1:\n",
        "#       result_df = pd.concat(result_df)\n",
        "#     else:\n",
        "#       result_df = result_df[0]\n",
        "\n",
        "#     return result_df\n"
      ],
      "metadata": {
        "id": "355KO7kkK0tU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ddcd29df-e817-4dd3-d273-8a08c7320d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OLD ALGORITHM'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def eliminate_duplicates(labels, df):\n",
        "#     df_list = []\n",
        "#     for label in labels:\n",
        "#         df_lab = df[df['labels'] == label].copy(deep=True).reset_index(drop = True)\n",
        "#         df_list.append(df_lab)\n",
        "#     bad_indexes = []\n",
        "#     for i in range(len(df_list)-1):\n",
        "#       chg_i = list(df_list[i]['Number'].values)\n",
        "#       for j in range(i+1,len(df_list)):\n",
        "#         #if i!=j:\n",
        "#         chg_j = list(df_list[j]['Number'].values)\n",
        "#         if len(chg_j)>=len(chg_i):\n",
        "#           res_i = all([ele in chg_j for ele in chg_i])\n",
        "#           res_j = False\n",
        "#         else:\n",
        "#           res_j = all([ele in chg_i for ele in chg_j])\n",
        "#           res_i = False\n",
        "#         if res_i:\n",
        "#           bad_indexes.append(i)\n",
        "#           continue\n",
        "#         elif res_j:\n",
        "#           bad_indexes.append(j)\n",
        "\n",
        "\n",
        "\n",
        "#     result_df = [df_list[i] for i in range(len(df_list)) if i not in set(bad_indexes)]\n",
        "#     if len(result_df)>1:\n",
        "#       result_df = pd.concat(result_df)\n",
        "#     else:\n",
        "#       result_df = result_df[0]\n",
        "#     return result_df"
      ],
      "metadata": {
        "id": "W_4DQfi3fUGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def clusterize(df_with_labels,df_clean):\n",
        "#   clusters = {}\n",
        "#   #Initialize labels column (Poteva essere un problema crearlo on the spot come prima?)\n",
        "#   df_clean['labels'] = 0\n",
        "#   for i in range(len(list(df_clean['BoW']))):\n",
        "#     similar_indices = np.argwhere(scores[:, i] > similarity_threshold)\n",
        "#     #It gives me back a list of lists where each list contains a single element being the row where the score was higher or equal to similarity score\n",
        "#     similar_indices = [indices[0] for indices in similar_indices ] #I take only the first one\n",
        "#     # Create a new cluster with the query sentence and similar sentences\n",
        "#     cluster_label = f'Gruppo_{i}'\n",
        "#     clusters[cluster_label] = [i]  # Add the query sentence index to the cluster\n",
        "#     df_clean.loc[i, 'labels'] = cluster_label # Add the label to the query sentence\n",
        "#     for idx in similar_indices:\n",
        "#       if idx != i:  # Exclude the query sentence itself\n",
        "#         clusters[cluster_label].append(idx)\n",
        "#         df_clean.loc[idx, 'labels'] = cluster_label  # Add the label to the similar sentences\n",
        "#     df_with_labels = pd.concat([df_with_labels,df_clean.loc[similar_indices]], ignore_index=True)\n",
        "#     df_with_labels.drop('BoW',axis=1,inplace= True)\n",
        "#   print(f\"BEFORE DUPLICATES REMOVAL {df_with_labels.shape[0]}\")\n",
        "#   df_with_labels = eliminate_duplicates(df_with_labels)\n",
        "#   print(f\"END NUMBER ELEMENTS {df_with_labels.shape[0]}\")\n",
        "#   print(\"////////\\n///////\")\n",
        "#   return df_with_labels"
      ],
      "metadata": {
        "id": "GGceJS-T0fsJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}